# past_issue_rag.py

import os
import json
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# 2. ì„¤ì •ê°’
EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "lastproject")
NAMESPACE = "past_issue"
NEWS_JSON_PATH = "data2/2025.07.23_12.15.39_BigKinds_current_issues.json"
PAST_ISSUE_DB_PATH = "data/Past_news.csv"

# 3. ë²¡í„° ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´
embedding = OpenAIEmbeddings(model=EMBEDDING_MODEL)
vector_store = PineconeVectorStore(
    index_name=INDEX_NAME,
    embedding=embedding,
    namespace=NAMESPACE
)

# 4. ê³¼ê±° ì´ìŠˆ DB ë¡œë”©
df = pd.read_csv(PAST_ISSUE_DB_PATH)
issue_dict = dict(zip(df["Issue_name"], df["Contents"] + "\n\nìƒì„¸: " + df["Contentes(Spec)"]))
valid_issue_names = list(df["Issue_name"].unique())

# 5. AI Agent 1: ê´€ë ¨ ê³¼ê±° ì´ìŠˆ í›„ë³´ ì¶”ì¶œ
def extract_candidate_past_issues(news_content, issue_list, top_k=10):
    """AI Agentê°€ ë‰´ìŠ¤ ë‚´ìš©ì„ ë³´ê³  ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³¼ê±° ì´ìŠˆë“¤ì„ ì¶”ì¶œ"""
    
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë„ˆëŠ” í˜„ì¬ ë‰´ìŠ¤ì™€ ê³¼ê±° ì´ìŠˆì˜ ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼.
ì£¼ì–´ì§„ í˜„ì¬ ë‰´ìŠ¤ ë‚´ìš©ì„ ë¶„ì„í•˜ê³ , ì œê³µëœ ê³¼ê±° ì´ìŠˆ ë¦¬ìŠ¤íŠ¸ì—ì„œ ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì´ìŠˆë“¤ì„ ì„ ë³„í•´ì•¼ í•´.

ê´€ë ¨ì„± íŒë‹¨ ê¸°ì¤€:
1. ìœ ì‚¬í•œ ì‹œì¥ ìƒí™©: ê³¼ê±° ì´ìŠˆì™€ í˜„ì¬ ìƒí™©ì´ ìœ ì‚¬í•œ ì‹œì¥ í™˜ê²½ì¸ê°€?
2. ë™ì¼í•œ ì‚°ì—…/ê¸°ì—… ì˜í–¥: ê°™ì€ ì‚°ì—…ì´ë‚˜ ìœ ì‚¬í•œ ê¸°ì—…ë“¤ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ê°€?
3. ì •ì±…/ê²½ì œì  ìœ ì‚¬ì„±: ì •ì±… ë³€í™”ë‚˜ ê²½ì œì  ìš”ì¸ì´ ìœ ì‚¬í•œê°€?
4. íˆ¬ìì ì‹¬ë¦¬: íˆ¬ììë“¤ì˜ ë°˜ì‘ì´ë‚˜ ì‹œì¥ ì‹¬ë¦¬ê°€ ë¹„ìŠ·í•œê°€?"""),
        ("human", """
[í˜„ì¬ ë‰´ìŠ¤ ë‚´ìš©]
{news}

[ê³¼ê±° ì´ìŠˆ ë¦¬ìŠ¤íŠ¸]
{issues}

ìœ„ í˜„ì¬ ë‰´ìŠ¤ì™€ ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê³¼ê±° ì´ìŠˆë¥¼ {top_k}ê°œ ì„ ë³„í•´ì£¼ì„¸ìš”.
ê° ê³¼ê±° ì´ìŠˆì— ëŒ€í•´ ê´€ë ¨ì„± ì ìˆ˜(1-10ì )ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "candidates": [
    {{"issue": "ì´ìŠˆëª…", "score": ì ìˆ˜, "reason": "ê´€ë ¨ì„± ì´ìœ "}},
    ...
  ]
}}""")
    ])
    
    parser = JsonOutputParser()
    chain = prompt | llm | parser
    
    result = chain.invoke({
        "news": news_content,
        "issues": ", ".join(issue_list),
        "top_k": top_k
    })
    
    return result["candidates"]

# 6. AI Agent 2: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ AI í›„ë³´ ê²°í•©
def combine_and_validate_results(news_content, vector_candidates, ai_candidates, issue_dict):
    """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ AI í›„ë³´ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ë„ì¶œ"""
    
    # ë²¡í„° í›„ë³´ì™€ AI í›„ë³´ ê²°í•©
    all_candidates = {}
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ì¶”ê°€
    for candidate in vector_candidates:
        name = candidate["name"]
        all_candidates[name] = {
            "name": name,
            "vector_similarity": candidate["similarity"],
            "ai_score": 0,
            "ai_reason": "",
            "description": candidate["description"]
        }
    
    # AI í›„ë³´ ì¶”ê°€/ì—…ë°ì´íŠ¸
    for candidate in ai_candidates:
        name = candidate["issue"]
        if name in all_candidates:
            all_candidates[name]["ai_score"] = candidate["score"]
            all_candidates[name]["ai_reason"] = candidate["reason"]
        elif name in issue_dict:  # ìœ íš¨í•œ ì´ìŠˆëª…ì¸ ê²½ìš°ë§Œ
            all_candidates[name] = {
                "name": name,
                "vector_similarity": 0,
                "ai_score": candidate["score"],
                "ai_reason": candidate["reason"],
                "description": issue_dict[name]
            }
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ë²¡í„° ìœ ì‚¬ë„ + AI ì ìˆ˜)
    for candidate in all_candidates.values():
        # ë²¡í„° ìœ ì‚¬ë„ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ ì •ê·œí™”
        normalized_vector = candidate["vector_similarity"] / 10
        # AI ì ìˆ˜ëŠ” ì´ë¯¸ 10ì  ë§Œì 
        ai_score = candidate["ai_score"]
        
        # ê°€ì¤‘í‰ê·  (AI ì ìˆ˜ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
        candidate["final_score"] = round((normalized_vector * 0.3 + ai_score * 0.7), 1)
    
    # ìµœì¢… ì ìˆ˜ë¡œ ì •ë ¬
    sorted_candidates = sorted(all_candidates.values(), 
                              key=lambda x: x["final_score"], 
                              reverse=True)
    
    return sorted_candidates[:3]  # ìƒìœ„ 3ê°œë§Œ ë°˜í™˜

# 7. ë‰´ìŠ¤ ì´ìŠˆ ë¡œë”© ë° ë¶„ì„
with open(NEWS_JSON_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

for idx, issue in enumerate(data["issues"]):
    print(f"\n{'='*80}")
    print(f"ğŸ“° ì´ìŠˆ {idx+1}/10: {issue['ì œëª©']}")
    print(f"{'='*80}")
    
    query = f"{issue['ì œëª©']}\n{issue['ë‚´ìš©']}"

    # Step 1: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ì¶”ì¶œ
    results = vector_store.similarity_search_with_score(query, k=10)
    
    vector_candidates = []
    for doc, score in results:
        content = doc.page_content.replace('\ufeff', '').replace('ï»¿', '')
        
        if "Issue_name:" in content:
            lines = content.split("\n")
            for line in lines:
                if "Issue_name:" in line:
                    issue_name = line.replace("Issue_name:", "").strip()
                    if issue_name in issue_dict:
                        # ì¤‘ë³µ ì²´í¬
                        if not any(c["name"] == issue_name for c in vector_candidates):
                            similarity_percentage = round((1 - score) * 100, 1)
                            
                            content_parts = content.split("Contents:")
                            issue_detail = content_parts[1].strip() if len(content_parts) > 1 else issue_dict[issue_name]
                            
                            vector_candidates.append({
                                "name": issue_name,
                                "similarity": similarity_percentage,
                                "description": issue_detail
                            })
                    break

    # Step 2: AI Agentë¡œ ê´€ë ¨ ê³¼ê±° ì´ìŠˆ í›„ë³´ ì¶”ì¶œ
    print("ğŸ¤– AI Agentê°€ ê´€ë ¨ ê³¼ê±° ì´ìŠˆë¥¼ ë¶„ì„ ì¤‘...")
    ai_candidates = extract_candidate_past_issues(query, valid_issue_names, top_k=10)
    
    # Step 3: ê²°ê³¼ ê²°í•© ë° ê²€ì¦
    final_candidates = combine_and_validate_results(query, vector_candidates, ai_candidates, issue_dict)
    
    if not final_candidates:
        print("âŒ ê´€ë ¨ ê³¼ê±° ì´ìŠˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        continue
    
    # Step 4: ìµœì¢… ë¶„ì„ ê²°ê³¼ ìƒì„±
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    analysis_prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” ê³¼ê±° ì´ìŠˆì™€ í˜„ì¬ ë‰´ìŠ¤ì˜ ì—°ê´€ì„±ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ì •í™•í•˜ê³  ì‹ ë¢°ì„± ìˆëŠ” ë¶„ì„ì„ ì œê³µí•´ì•¼ í•´."),
        ("human", """
[í˜„ì¬ ì´ìŠˆ ë‚´ìš©]
{news}

[ì„ ë³„ëœ ê´€ë ¨ ê³¼ê±° ì´ìŠˆ]
{past_issues}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

**í˜„ì¬ ì´ìŠˆ ìš”ì•½**
(í•µì‹¬ ë‚´ìš© 1-2ë¬¸ì¥)

**ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ë¶„ì„**
- **ê³¼ê±°ì´ìŠˆ1** (ì‹ ë¢°ë„: Xì ): í˜„ì¬ ìƒí™©ê³¼ì˜ ìœ ì‚¬ì ê³¼ ì°¨ì´ì  ì„¤ëª…
- **ê³¼ê±°ì´ìŠˆ2** (ì‹ ë¢°ë„: Xì ): í˜„ì¬ ìƒí™©ê³¼ì˜ ìœ ì‚¬ì ê³¼ ì°¨ì´ì  ì„¤ëª…  
- **ê³¼ê±°ì´ìŠˆ3** (ì‹ ë¢°ë„: Xì ): í˜„ì¬ ìƒí™©ê³¼ì˜ ìœ ì‚¬ì ê³¼ ì°¨ì´ì  ì„¤ëª…

**ì‹œì‚¬ì **: ê³¼ê±° ì‚¬ë¡€ë¥¼ í†µí•´ ì˜ˆìƒë˜ëŠ” ì‹œì¥ ë°˜ì‘ì´ë‚˜ íˆ¬ì ì „ëµ
""")
    ])
    
    past_issues_text = "\n".join([
        f"- {c['name']} (ì¢…í•©ì ìˆ˜: {c['final_score']}/10, ë²¡í„°ìœ ì‚¬ë„: {c['vector_similarity']}%, AIì ìˆ˜: {c['ai_score']}/10)\n"
        f"  AI íŒë‹¨ ê·¼ê±°: {c['ai_reason']}\n"
        f"  ê³¼ê±° ì´ìŠˆ ë‚´ìš©: {c['description'][:200]}..."
        for c in final_candidates
    ])
    
    parser = StrOutputParser()
    analysis_chain = analysis_prompt | llm | parser
    
    response = analysis_chain.invoke({
        "news": query,
        "past_issues": past_issues_text
    })
    
    print(response)
    
    # ë””ë²„ê¹… ì •ë³´
    print(f"\nğŸ“Š ìƒì„¸ ì ìˆ˜:")
    for i, c in enumerate(final_candidates, 1):
        print(f"{i}. {c['name']}: ì¢…í•©{c['final_score']}/10 (ë²¡í„° ìœ ì‚¬ë„ {c['vector_similarity']}% + AI ë¶„ì„ ì ìˆ˜ {c['ai_score']}/10)")
    
    if idx < len(data["issues"]) - 1:
        print(f"\n{'-'*80}")

print(f"\nğŸ‰ ì´ {len(data['issues'])}ê°œ ì´ìŠˆ ë¶„ì„ ì™„ë£Œ!")