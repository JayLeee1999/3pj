# industry_rag.py

import os
import json
import pandas as pd
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# 2. ì„¤ì •ê°’
EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "lastproject")
NAMESPACE = "industry"
NEWS_JSON_PATH = "data2/2025.07.23_12.15.39_BigKinds_current_issues.json"
INDUSTRY_DB_PATH = "data/ì‚°ì—…DB.v.0.3.csv"

# 3. ë²¡í„° ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´
embedding = OpenAIEmbeddings(model=EMBEDDING_MODEL)
vector_store = PineconeVectorStore(
    index_name=INDEX_NAME,
    embedding=embedding,
    namespace=NAMESPACE
)

# 4. ì‚°ì—… DB ë¡œë”©
df = pd.read_csv(INDUSTRY_DB_PATH)
industry_dict = dict(zip(df["KRX ì—…ì¢…ëª…"], df["ìƒì„¸ë‚´ìš©"]))
valid_krx_names = set(df["KRX ì—…ì¢…ëª…"].unique())

# 5. ë‰´ìŠ¤ ì´ìŠˆ ë¡œë”©
with open(NEWS_JSON_PATH, "r", encoding="utf-8") as f:
    data = json.load(f)

# ëª¨ë“  ì´ìŠˆì— ëŒ€í•´ ë¶„ì„ ìˆ˜í–‰
for idx, issue in enumerate(data["issues"]):
    print(f"\n{'='*80}")
    print(f"ğŸ“° ì´ìŠˆ {idx+1}/10: {issue['ì œëª©']}")
    print(f"{'='*80}")
    
    query = f"{issue['ì œëª©']}\n{issue['ë‚´ìš©']}"

    # 6. ìœ ì‚¬ ì‚°ì—… ë²¡í„° ê²€ìƒ‰ (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)
    results = vector_store.similarity_search_with_score(query, k=5)

    # 7. ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìƒì„¸ë‚´ìš© ì¶”ì¶œ
    matched_industries = []
    for doc, score in results:
        content = doc.page_content
        
        # BOM ë¬¸ì ì œê±°
        content = content.replace('\ufeff', '').replace('ï»¿', '')
        
        # ì‚°ì—…ëª…ê³¼ ìƒì„¸ë‚´ìš© ì¶”ì¶œ
        industry_name = None
        industry_detail = None
        
        if "KRX ì—…ì¢…ëª…:" in content and "ìƒì„¸ë‚´ìš©:" in content:
            lines = content.split("\n")
            
            # ì‚°ì—…ëª… ì¶”ì¶œ
            for line in lines:
                if "KRX ì—…ì¢…ëª…:" in line:
                    industry_name = line.replace("KRX ì—…ì¢…ëª…:", "").strip()
                    break
            
            # ìƒì„¸ë‚´ìš© ì¶”ì¶œ (ë²¡í„°ì—ì„œ ê°€ì ¸ì˜¨ ì‹¤ì œ ì„¤ëª…)
            content_parts = content.split("ìƒì„¸ë‚´ìš©:")
            if len(content_parts) > 1:
                industry_detail = content_parts[1].strip()
        
        # ìœ íš¨í•œ ì‚°ì—…ëª…ì¸ì§€ í™•ì¸ ë° ì¤‘ë³µ ë°©ì§€
        if industry_name and industry_name in valid_krx_names:
            # ì´ë¯¸ ì¶”ê°€ëœ ì‚°ì—…ì¸ì§€ í™•ì¸
            already_added = any(item['name'] == industry_name for item in matched_industries)
            if not already_added:
                # ìœ ì‚¬ë„ë¥¼ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë†’ìŒ)
                similarity_percentage = round((1 - score) * 100, 1)
                matched_industries.append({
                    "name": industry_name, 
                    "description": industry_detail or industry_dict.get(industry_name, "ì„¤ëª… ì—†ìŒ"),
                    "similarity": similarity_percentage
                })

    print(f"ìµœì¢… ë§¤ì¹­ëœ ì‚°ì—… ìˆ˜: {len(matched_industries)}")

    # 8. ë§¤ì¹­ëœ ì‚°ì—…ì´ ì—†ì„ ê²½ìš° ì²˜ë¦¬
    if not matched_industries:
        print("âŒ ë§¤ì¹­ëœ ì‚°ì—…ì´ ì—†ìŠµë‹ˆë‹¤.")
        continue

    # 9. GPT ì…ë ¥ êµ¬ì„± (ìƒìœ„ 3ê°œë§Œ)
    top_industries = matched_industries[:3]
    industry_list_text = "\n".join([f"{i+1}. {item['name']} (ìœ ì‚¬ë„: {item['similarity']}%)" for i, item in enumerate(top_industries)])
    industry_reason_text = "\n\n".join([f"**{item['name']}** (ìœ ì‚¬ë„: {item['similarity']}%)\n{item['description']}" for item in top_industries])

    # 10. GPT ë¶„ì„ í”„ë¡¬í”„íŠ¸ (ê·¼ê±° í¬í•¨)
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë„ˆëŠ” í•œêµ­ ì‚°ì—… ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ë¦¬ì„œì¹˜ ì• ë„ë¦¬ìŠ¤íŠ¸ì•¼. 
    ì¤‘ìš”: ë°˜ë“œì‹œ ì œê³µëœ ì‚°ì—…ëª…ë§Œ ì‚¬ìš©í•˜ê³ , ì œê³µëœ ì‚°ì—… ì„¤ëª…ì„ ê·¼ê±°ë¡œ ê´€ë ¨ì„±ì„ ì„¤ëª…í•´ì•¼ í•´."""),
        ("human", """
    [ì´ìŠˆ ë‚´ìš©]
    {news}

    [ê´€ë ¨ ì‚°ì—…ëª… (ìœ ì‚¬ë„ í¬í•¨)]
    {industry_list}

    [ê° ì‚°ì—…ì˜ ìƒì„¸ ì„¤ëª… (ê·¼ê±°ìë£Œ)]
    {industry_reasons}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

    **ì´ìŠˆ ìš”ì•½**
    (1-2ë¬¸ì¥ìœ¼ë¡œ ê°„ëµíˆ)

    **ê´€ë ¨ ì‚°ì—… ë¶„ì„**
    - **ì‚°ì—…ëª…1** (ìœ ì‚¬ë„: X%): (ì œê³µëœ ì‚°ì—… ì„¤ëª…ì„ ê·¼ê±°ë¡œ ì™œ ì´ ì´ìŠˆì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì„¤ëª…)
    - **ì‚°ì—…ëª…2** (ìœ ì‚¬ë„: X%): (ì œê³µëœ ì‚°ì—… ì„¤ëª…ì„ ê·¼ê±°ë¡œ ì™œ ì´ ì´ìŠˆì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì„¤ëª…)  
    - **ì‚°ì—…ëª…3** (ìœ ì‚¬ë„: X%): (ì œê³µëœ ì‚°ì—… ì„¤ëª…ì„ ê·¼ê±°ë¡œ ì™œ ì´ ì´ìŠˆì™€ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì„¤ëª…)

    **ì£¼ì˜: ë°˜ë“œì‹œ ìœ„ì— ì œê³µëœ ì‚°ì—…ëª…ê³¼ ì„¤ëª…ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.**
    """)
    ])
    parser = StrOutputParser()
    chain = prompt | llm | parser

    # 11. GPT í˜¸ì¶œ ë° ê²°ê³¼ ì¶œë ¥
    response = chain.invoke({
        "news": query,
        "industry_list": industry_list_text,
        "industry_reasons": industry_reason_text
    })

    print(response)
    
    # ê° ì´ìŠˆ ì‚¬ì´ì— êµ¬ë¶„ì„  ì¶”ê°€
    if idx < len(data["issues"]) - 1:
        print(f"\n{'-'*80}")

print(f"\nğŸ‰ ì´ {len(data['issues'])}ê°œ ì´ìŠˆ ë¶„ì„ ì™„ë£Œ!")